{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering over mobb.ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.document_loaders import ReadTheDocsLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command is used to download web pages and other content from a website, and in this case, it will download all the .html files from the https://mobb.ninja/docs/ URL and any subdirectories recursively.\n",
    "\n",
    "`wget -r -A.html https://mobb.ninja/docs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.document_loaders.readthedocs.ReadTheDocsLoader"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReadTheDocsLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Any, List, Optional\n",
    "import html\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "class MobbNinjaDocsLoader(ReadTheDocsLoader):\n",
    "    \"\"\"Loader that loads ReadTheDocs documentation directory dump.\"\"\"\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load documents.\"\"\"\n",
    "        from bs4 import BeautifulSoup\n",
    "\n",
    "        def _clean_data(data: str) -> str:\n",
    "            soup = BeautifulSoup(data, **self.bs_kwargs)\n",
    "            # text = soup.find_all(\"main\", {\"id\": \"main-content\"})\n",
    "            article_tag = soup.find(\"article\")\n",
    "            # text = article_tag.get_text()\n",
    "            if article_tag and len(article_tag) != 0:\n",
    "                text = article_tag.get_text()\n",
    "                # Replace HTML entities with their corresponding characters\n",
    "                text = html.unescape(text)\n",
    "                # Format the text for better readability\n",
    "                text = text.strip().replace('\\n', ' ')\n",
    "            else:\n",
    "                text = \"\"\n",
    "            return \"\\n\".join([t for t in text.split(\"\\n\") if t])\n",
    "\n",
    "        docs = []\n",
    "        for p in Path(self.file_path).rglob(\"*\"):\n",
    "            if p.is_dir():\n",
    "                continue\n",
    "            with open(p, encoding=self.encoding, errors=self.errors) as f:\n",
    "                text = _clean_data(f.read())\n",
    "            metadata = {\"source\": str(p)}\n",
    "            docs.append(Document(page_content=text, metadata=metadata))\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = MobbNinjaDocsLoader(\"mobb.ninja/docs/\", features='html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MobbNinjaDocsLoader at 0x7fe30630e9a0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Documentation from the MOBBQuickstarts / Getting StartedRed Hat OpenShift on AWS (ROSA)Azure Red Hat OpenShift (ARO)Advanced Managed OpenShiftROSADeploying ROSA in Private Link modeAdd Public Ingress to Private Link ClusterDeploying ROSA in STS modeDeploying ROSA in STS mode with Private LinkDeploying ROSA in STS mode with custom KMS KeyInstalling the AWS Load Balancer Operator on ROSAAssign Egress IP for External TrafficAdding AWS WAF in front of ROSA / OSDUse AWS Secrets CSI with ROSA in STS modeUse AWS CloudWatch Agent to push prometheus metrics to AWS CloudWatchFederating ROSA metrics to Prometheus with customer alertingConfiguring Alerts for User Workloads in ROSA 4.9.xAWS EFS on ROSAUsing Amazon Web Services Elastic File System (EFS) on ROSAUsing the AWS EFS CSI Driver Operator on ROSA 4.10.xConfiguring a ROSA cluster to pull images from AWS Elastic Container Registry (ECR)Configuring a ROSA cluster to use ECR secret operatorDeploy and use the AWS Kubernetes Controller S3 controllerDeploy ROSA in an AWS Secure Environment Accelerator (ASEA) Landing ZoneVerify Required Permissions for a ROSA STS deploymentSTS OIDC flow in ROSA OperatorsDynamic Certificates for ROSA Custom DomainExternal DNS for ROSA Custom DomainSecurity Reference Architecture for ROSAConfigure ROSA for Nvidia GPU WorkloadsARODeploying private ARO Cluster with Jump Host accessUsing the Egressip Ipam Operator with a Private ARO ClusterConsiderations for Disaster Recovery with AROGetting Started with the Azure Key Vault CSI DriverDeploy and use the Azure Service Operator V1(ASO)Deploy and use the Azure Service Operator V2(ASO)Create an additional Ingress Controller for AROConfigure the Managed Upgrade OperatorConfigure ARO with Azure NetApp Trident OperatorIBM Cloud Paks for Data Operator SetupInstall ARO with Custom Domain using LetsEncrypt with cert managerConfigure ARO for Nvidia GPU WorkloadsConfigure ARO with Azure Front DoorCreate a point to site VPN connection for an ARO ClusterConfigure access to ARO Image RegistryConfigure ARO with OpenShift Data FoundationSetting Up Quay on an ARO Cluster using Azure Container Storagevia CLIvia GUIConfigure ARO with Azure PolicyCreate infrastructure nodes on an ARO ClusterConfigure a load balancer service to use a static public IPUpgrade a disconnected ARO clusterGCPDeploy OSD in GCP using Pre-Existent VPC and SubnetsUsing Filestore with OpenShift Dedicated in GCPAdvanced Cluster Manager (ACM)Deploy ACM Observability to a ROSA clusterObservabilityDeploy Grafana on OpenShift 4Configuring Alerts for User WorkloadsROSA 4.9.x, 4.10.xROSA 4.11+Federating ROSA metrics to S3Federating ROSA metrics to Prometheus with customer alertingFederating ROSA metrics to AWS PrometheusConfigure ROSA STS Cluster Logging to CloudWatchFederating ARO metrics to Azure FilesSending ARO cluster logs to Azure Log AnalyticsUse AWS CloudWatch Agent to push prometheus metrics to AWS CloudWatchSecurityKubernetes Secret Store CSI DriverJust the CSI itself+ HashiCorp CSI+ AWS Secrets CSI with ROSA in STS mode+ Azure Key Vault CSI DriverConfiguring Specific Identity ProvidersConfigure GitLab as an identity provider for ROSA/OSDConfigure GitLab as an identity provider for AROConfigure Azure AD as an identity provider for AROConfigure Azure AD as an identitiy provider for ARO with group claimsConfigure Azure AD as an identitiy provider for ROSA with group claimsConfigure Azure AD as an identity provider for ROSA/OSDConfigure Azure AD as an identity provider for ARO via the CLIConfiguring Group SynchronizationUsing Group Sync Operator with Azure Active Directory and ROSA/OSDUsing Group Sync Operator with Okta and ROSA/OSDDeploying Advanced Security for Kubernetes in ROSA/ARODeploying ACS in ROSA/AROApplicationsDeploying Astronomer to OpenShiftDeploying 3scale API Management to ROSA/OSDIngressConfigure a custom ingress TLS profile for ROSA/OSDData Science on Jupyter Notebook on OpenShiftPrerequistes and ConceptsBuild minimal notebookJupyterHub notebook with GPUMiscellaneousDemonstrating GitOps - ArgoCDMigrate Kubernetes Applications with Konveyor CraneRed Hat Cost Management for Cloud ServicesDeploy OpenShift Advanced Data Protection on a ROSA STS clusterAzure DevOps with Managed OpenShiftFixes / WorkaroundsHere be dragons - use at your own riskFix Cluster Logging Operator Addon for ROSA STS ClustersStop default router from serving custom domain routes', metadata={'source': 'mobb.ninja/docs/index.html'})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Azure Red Hat OpenShiftAzure Red Hat OpenShift is a fully managed, cloud-based service that allows users to quickly and easily deploy and manage containerized applications on the Azure platform. This product is a collaboration between Microsoft Azure and Red Hat, two industry leaders in cloud computing and open source software development. With Azure Red Hat OpenShift, users can leverage the benefits of Azure’s global infrastructure and scalability, as well as Red Hat’s expertise in containerization and open source technologies. This product is ideal for businesses that want to take advantage of the agility and flexibility of containers, but also need the reliability and security of a trusted cloud provider.', metadata={'source': 'mobb.ninja/docs/aro/index.html'})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Upgrade a disconnected ARO clusterAaron Green & Kevin Collins03/06/2023BackgroundOne of the great features of ARO is that you can create ‘disconnected’ clusters with no connectivity to the Internet. Out of the box, the ARO service mirrors all the code repositories to build OpenShift clusters to Azure Container Registry. This means ARO is built without having to reach out to the Internet as the images to build OpenShift are pulled via the Azure private network.When you upgrade a cluster, OpenShift needs to call out to the Internet to get an upgrade graph to see what options you have to upgrade the cluster. This of course breaks the concept of having a disconnected cluster. This guide goes through how to upgrade ARO without having the cluster reach out to the Internet and maintaining the disconnected nature of an ARO cluster.PrerequisitesA Private Azure Red Hat OpenShift cluster with no Internet ConnectivityCheck upgrade pathNOTE: This step is VERY important. In a future step, you need to have already validated that the version you are upgrading to is safe to do so.First check which version your cluster is at:oc get clusterversion version Note the server version.NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS version   4.10.40   True        False         14h     Cluster version is 4.10.40 Verify you are selecting a valid version to upgrade to. Go to https://access.redhat.com/labsinfo/ocpupgradegraphUnder Channel, select the stable minor version that you want to upgrade the cluster to. In this example, we have a 4.10 cluster that is at patch level 40 and we want to upgrade it to 4.11. Note that you can also update patch versions.On the next screen, start by selecting the version your cluster is at. In the example below, we’ll select 4.10.40.Then select the version you want to upgrade to ensure there is a green line showing the upgrade path is recommended. In the example, we select version 4.11.28.Upgrade the clusterNOTE: In step 2 below, you are explicitly telling the cluster to upgrade to an image digest value and must use the --force flag because the cluster has no ability to validate the image digest value without Internet connectivity. Please ensure you have completed the step to check the upgrade path so that you are upgrading the cluster to a version with a supported path from the current cluster version you’re on.Retrieve the image digest of the OpenShift version you want to upgrade to:export VERSION=4.11.28 # Update to your desired version  curl -s https://mirror.openshift.com/pub/openshift-v4/clients/ocp/\"${VERSION}\"/release.txt | grep \"Pull From:\" Expected Output:Pull From: quay.io/openshift-release-dev/ocp-release@sha256:85238bc3eddb88e958535597dbe8ec6f2aa88aa1713c2e1ee7faf88d1fefdac0 Perform the UpgradeSet the image to the desired values from the above command.oc adm upgrade --allow-explicit-upgrade --to-image=quay.io/openshift-release-dev/ocp-release@sha256:1c3913a65b0a10b4a0650f54e545fe928360a94767acea64c0bd10faa52c945a --force Check the status of the scheduled upgradeoc get clusterversion version When the upgrade is complete you will see the following:NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS version   4.11.28    True        False         161m    Cluster version is 4.11.28', metadata={'source': 'mobb.ninja/docs/aro/upgrade-disconnected-aro/index.html'})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.text_splitter.RecursiveCharacterTextSplitter at 0x7fe30739f130>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Documentation from the MOBBQuickstarts / Getting StartedRed Hat OpenShift on AWS (ROSA)Azure Red Hat OpenShift (ARO)Advanced Managed OpenShiftROSADeploying ROSA in Private Link modeAdd Public Ingress to Private Link ClusterDeploying ROSA in STS modeDeploying ROSA in STS mode with Private LinkDeploying ROSA in STS mode with custom KMS KeyInstalling the AWS Load Balancer Operator on ROSAAssign Egress IP for External TrafficAdding AWS WAF in front of ROSA / OSDUse AWS Secrets CSI with ROSA in STS modeUse AWS CloudWatch Agent to push prometheus metrics to AWS CloudWatchFederating ROSA metrics to Prometheus with customer alertingConfiguring Alerts for User Workloads in ROSA 4.9.xAWS EFS on ROSAUsing Amazon Web Services Elastic File System (EFS) on ROSAUsing the AWS EFS CSI Driver Operator on ROSA 4.10.xConfiguring a ROSA cluster to pull images from AWS Elastic Container Registry (ECR)Configuring a ROSA cluster to use ECR secret operatorDeploy and use the AWS Kubernetes Controller S3', metadata={'source': 'mobb.ninja/docs/index.html'})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"page_content\": \"Documentation from the MOBBQuickstarts / Getting StartedRed Hat OpenShift on AWS (ROSA)Azure Red Hat OpenShift (ARO)Advanced Managed OpenShiftROSADeploying ROSA in Private Link modeAdd Public Ingress to Private Link ClusterDeploying ROSA in STS modeDeploying ROSA in STS mode with Private LinkDeploying ROSA in STS mode with custom KMS KeyInstalling the AWS Load Balancer Operator on ROSAAssign Egress IP for External TrafficAdding AWS WAF in front of ROSA / OSDUse AWS Secrets CSI with ROSA in STS modeUse AWS CloudWatch Agent to push prometheus metrics to AWS CloudWatchFederating ROSA metrics to Prometheus with customer alertingConfiguring Alerts for User Workloads in ROSA 4.9.xAWS EFS on ROSAUsing Amazon Web Services Elastic File System (EFS) on ROSAUsing the AWS EFS CSI Driver Operator on ROSA 4.10.xConfiguring a ROSA cluster to pull images from AWS Elastic Container Registry (ECR)Configuring a ROSA cluster to use ECR secret operatorDeploy and use the AWS Kubernetes Controller S3\", \"metadata\": {\"source\": \"mobb.ninja/docs/index.html\"}}'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: chroma_vector_store\n"
     ]
    }
   ],
   "source": [
    "# Prerequisite: chromadb module is required. install `pip install chromadb`\n",
    "# Create a Chroma vectorstore from a raw documents.\n",
    "# If a persist_directory is specified, the collection will be persisted there.\n",
    "# Otherwise, the data will be ephemeral in-memory.\n",
    "\n",
    "# also including the source as part of metadata \n",
    "docsearch = Chroma.from_documents(documents, embedding=embeddings, collection_name='mobbninja',\n",
    "                  metadatas=[{\"source\": f\"{i}-pl\"} for i in range(len(documents))],\n",
    "                  persist_directory='chroma_vector_store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question-answering with sources over an index\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': ' To create a disconnected ARO cluster, you need to follow the steps outlined in the guide \"Upgrade a disconnected ARO cluster\" on mobb.ninja/docs/aro/upgrade-disconnected-aro/index.html.\\n',\n",
       " 'sources': 'mobb.ninja/docs/aro/upgrade-disconnected-aro/index.html'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"question\": \"How can I create disconnected ARO cluster\"}, return_only_outputs=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mispelling typo clustere instead of cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \" I don't know.\\n\", 'sources': 'N/A'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"question\": \"How can I create disconnected ARO clustere\"}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROSA - Use Cases around AWS Load Balancer Controller"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the page containing the info https://mobb.ninja/docs/rosa/aws-load-balancer-operator/\n",
    "\n",
    "```\n",
    "AWS Load Balancer Controller is a controller to help manage Elastic Load Balancers for a Kubernetes cluster.\n",
    "\n",
    "It satisfies Kubernetes Ingress resources by provisioning Application Load Balancers.\n",
    "It satisfies Kubernetes Service resources by provisioning Network Load Balancers.\n",
    "Compared with default AWS In Tree Provider, this controller is actively developed with advanced annotations for both ALB and NLB. Some advanced usecases are:\n",
    "\n",
    "Using native kubernetes ingress with ALB\n",
    "Integrate ALB with WAF\n",
    "Specify NLB source IP ranges\n",
    "Specify NLB internal IP address\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': ' Advanced use cases related to AWS Load Balancer Controller on ROSA include using native Kubernetes ingress with ALB, integrating ALB with WAF, specifying NLB source IP ranges, specifying NLB internal IP address, and configuring TLS and DNS for the ingress.\\n',\n",
       " 'sources': 'mobb.ninja/docs/rosa/aws-load-balancer-operator/index.html, mobb.ninja/docs/index.html, mobb.ninja/docs/rosa/waf/readme-complex/index.html, mobb.ninja/docs/rosa/waf/alb/index.html'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"question\": \"What are the advanced use cases related to AWS Load Balancer Controller on ROSA \"}, return_only_outputs=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROSA - User trying to configure GPU workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': \" I don't know.\\n\", 'sources': 'mobb.ninja/docs/index.html'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"question\": \"How can I configure ROSA for GPU workloads\"}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': ' ROSA does not support NVIDIA GPU workloads.\\n',\n",
       " 'sources': 'mobb.ninja/docs/rosa/gpu/index.html, mobb.ninja/docs/index.html, mobb.ninja/docs/aro/gpu/index.html, mobb.ninja/docs/index.html'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"question\": \"How can I configure ROSA for NVIDIA GPU workloads\"}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': ' Configuring ROSA for NVIDIA GPU workloads involves setting up entitlements to use the NVIDIA Operator, installing jq, moreutils, and gettext packages, and requesting GPU quota.\\n',\n",
       " 'sources': 'mobb.ninja/docs/rosa/gpu/index.html, mobb.ninja/docs/index.html'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"question\": \"Configure ROSA for NVIDIA GPU workloads\"}, return_only_outputs=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems providing additional context in the form of prompt is critical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "You can assume the question about the most recent state of the union address.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "template = \"\"\"You are an AI assistant for answering questions about documentation in mobb.ninja.\n",
    "You are given the following extracted parts of a long document and a question. Provide a conversational answer.\n",
    "If you don't know the answer, just say \"Hmm, I'm not sure.\" Don't try to make up an answer.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. Politely inform them that you are tuned to only answer questions about .\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer in Markdown:\"\"\"\n",
    "QA_PROMPT = PromptTemplate(template=template, input_variables=[\"question\", \"context\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.chat_vector_db.prompts import QA_PROMPT\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\",\n",
       " ['context', 'question'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_PROMPT.template, QA_PROMPT.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_chain = load_qa_with_sources_chain(\n",
    "#     llm=OpenAI(temperature=0),\n",
    "#     prompt=QA_PROMPT\n",
    "# )\n",
    "# qa = RetrievalQAWithSourcesChain(\n",
    "#     combine_documents_chain=qa_chain,\n",
    "#     retriever=docsearch.as_retriever())\n",
    "\n",
    "# query = \"What did the president say about Justice Breyer\"\n",
    "# qa({\"input_documents\": docsearch.as_retriever().get_relevant_documents(query),\n",
    "#     \"question\": query }, \n",
    "#    return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
